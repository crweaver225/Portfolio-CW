
<!DOCTYPE html>
<html lang="en-us"><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=52441&amp;path=livereload" data-no-instant defer></script>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  
  






  
  
  
    
  





  



<link rel="stylesheet" href="//localhost:52441/scss/main.css" />


<link rel="stylesheet" href="//localhost:52441/custom.css" />

  
<meta name="robots" content="index, follow">
    <meta name="googlebot" content="index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1">
    <meta name="bingbot" content="index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1">
  

<title>Building a Thread Pool in C&#43;&#43; | Christopher Weaver</title>


<meta name="author" content="Christopher Weaver">

<meta name="description" content="Portfolio site of Christopher Weaver.">
<link rel="canonical" href="//localhost:52441/engineering/building-a-thread-pool/">
<meta property="og:locale" content="en_US">
<meta property="og:type" content="article">
<meta property="og:title" content="Building a Thread Pool">
<meta property="og:description" content="One of my pet projects over the past few years has been my deep learning framework, built entirely in C&#43;&#43; link. Once I had an initial iteration that worked sequentially and could successfully train a neural network to accomplish specific tasks, I turned toward leveraging concurrency to speed up training. My first thought was to farm out computationally expensive tasks to different CPU cores, primarily focusing on functions that perform computations on matrices.">
<meta property="og:url" content="//localhost:52441/engineering/building-a-thread-pool/">
<meta property="article:published_time" content="2024-09-05T07:32:00-06:00">
  <meta property="article:modified_time" content="2024-09-05T07:32:00-06:00">
  


  <meta name="og:image" content="//localhost:52441/images/default.png"/>





  <meta property="og:see_also" content="//localhost:52441/engineering/functional-programming-in-c-/" /><meta property="og:see_also" content="//localhost:52441/engineering/building-a-log-utility-class-in-cpp/" /><meta property="og:see_also" content="//localhost:52441/engineering/concurrency-in-c-/" /><meta property="og:see_also" content="//localhost:52441/engineering/building-neural-networks-in-c-/" /><meta property="og:see_also" content="//localhost:52441/engineering/compile-time-programming-in-c-/" />
  


  <meta name="twitter:site" content="johndoestwitter">


  <meta name="twitter:creator" content="johndoestwitter">

<meta name="twitter:title" content="Building a Thread Pool">
<meta name="twitter:description" content="One of my pet projects over the past few years has been my deep learning framework, built entirely in C&#43;&#43; link. Once I had an initial iteration that worked sequentially and could successfully train a neural network to accomplish specific tasks, I turned toward leveraging concurrency to speed up training. My first thought was to farm out computationally expensive tasks to different CPU cores, primarily focusing on functions that perform computations on matrices.">



  <meta name="twitter:card" content="summary_large_image"/>
  <meta name="twitter:image" content="//localhost:52441/images/default.png"/>





  


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@graph": [
    {
      "@type": "Person",
      "@id": "//localhost:52441/#/schema/person/1",
      "name": "Christopher Weaver",
      "url": "//localhost:52441/",
      "image": {
        "@type": "ImageObject",
        "@id": "//localhost:52441/#/schema/image/1",
        "url": "//localhost:52441/images/default.png",
        "width": 453 ,
        "height": 455 ,
        "caption": "Christopher Weaver"
      }
    },
    {
      "@type": "WebSite",
      "@id": "//localhost:52441/#/schema/website/1",
      "url": "//localhost:52441/",
      "name": "Christopher Weaver",
      "description": "Portfolio site of Christopher Weaver.",
      "publisher": {
        "@id": "//localhost:52441/#/schema/person/1"
      }
    },
    {
      "@type": "WebPage",
      "@id": "//localhost:52441/engineering/building-a-thread-pool/",
      "url": "//localhost:52441/engineering/building-a-thread-pool/",
      "name": "Building a Thread Pool in C++",
      "description": "Portfolio site of Christopher Weaver.",
      "isPartOf": {
        "@id": "//localhost:52441/#/schema/website/1"
      },
      "about": {
        "@id": "//localhost:52441/#/schema/person/1"
      },
      "datePublished": "2024-09-05T07:32:00-06:00",
      "dateModified": "2024-09-05T07:32:00-06:00",
      "breadcrumb": {
        "@id": "//localhost:52441/engineering/building-a-thread-pool/#/schema/breadcrumb/1"
      },
      "primaryImageOfPage": {
        "@id": "//localhost:52441/engineering/building-a-thread-pool/#/schema/image/2"
      },
      "inLanguage": "en-US",
      "potentialAction": [{
        "@type": "ReadAction", "target": ["//localhost:52441/engineering/building-a-thread-pool/"]
      }]
    },
    {
      "@type": "BreadcrumbList",
      "@id": "//localhost:52441/engineering/building-a-thread-pool/#/schema/breadcrumb/1",
      "name": "Breadcrumbs",
      "itemListElement": [{
        "@type": "ListItem",
        "position":  1 ,
        "item": {
          "@type": "WebPage",
          "@id": "//localhost:52441/",
          "url": "//localhost:52441/",
          "name": "Home"
          }
        },{
        "@type": "ListItem",
        "position":  2 ,
        "item": {
          "@type": "WebPage",
          "@id": "//localhost:52441/engineering/",
          "url": "//localhost:52441/engineering/",
          "name": "Engineering"
          }
        },{
        "@type": "ListItem",
        "position":  3 ,
        "item": {
          "@id": "//localhost:52441/engineering/building-a-thread-pool/"
          }
        }]
    },
    {
      "@context": "https://schema.org",
      "@graph": [
        {
          "@type": "Article",
          "@id": "//localhost:52441/#/schema/article/1",
          "headline": "Building a Thread Pool in C++",
          "description": "",
          "isPartOf": {
            "@id": "//localhost:52441/engineering/building-a-thread-pool/"
          },
          "mainEntityOfPage": {
            "@id": "//localhost:52441/engineering/building-a-thread-pool/"
          },
          "datePublished": "2024-09-05T07:32:00-06:00",
          "dateModified": "2024-09-05T07:32:00-06:00",
          "author": {
            "@id": "//localhost:52441/#/schema/person/1"
          },          
          "publisher": {
            "@id": "//localhost:52441/#/schema/person/1"
          },
          "image": {
            "@id": "//localhost:52441/engineering/building-a-thread-pool/#/schema/image/2"
          }
        }
      ]
    },{
      "@context": "https://schema.org",
      "@graph": [
        {
          "@type": "ImageObject",
          "@id": "//localhost:52441/engineering/building-a-thread-pool/#/schema/image/2",
          "url": "//localhost:52441/images/default.png",
          "contentUrl": "//localhost:52441/images/default.png",
          "caption": "Building a Thread Pool in C++"
        }
      ]
    }
  ]
}
</script>
  

  

  
</head><body>
    <header class="container">
  <nav class="main-nav" id="js-navbar">
    <a class="logo" href="//localhost:52441/">Christopher Weaver</a>
    <ul class="menu" id="js-menu">
      
      
      
      <li class="menu-item">
        <span class="menu-link">Work<span class="drop-icon">▾</span></span>
        <ul class="sub-menu">
          
            <li class="menu-item">
              <a href="/projects/" class="menu-link">Projects</a>                  
            </li>
          
            <li class="menu-item">
              <a href="/about/" class="menu-link">About</a>                  
            </li>
          
        </ul>
      </li>
      
      
      
      <li class="menu-item">
        <span class="menu-link">Writing<span class="drop-icon">▾</span></span>
        <ul class="sub-menu">
          
            <li class="menu-item">
              <a href="/posts/" class="menu-link">All Posts</a>                  
            </li>
          
            <li class="menu-item">
              <a href="/engineering/" class="menu-link">Engineering</a>                  
            </li>
          
            <li class="menu-item">
              <a href="/philosophy/" class="menu-link">Philosophy</a>                  
            </li>
          
        </ul>
      </li>
      
      
      
      <li class="menu-item">
        <span class="menu-link">Explore<span class="drop-icon">▾</span></span>
        <ul class="sub-menu">
          
            <li class="menu-item">
              <a href="/categories/" class="menu-link">Categories</a>                  
            </li>
          
            <li class="menu-item">
              <a href="/tags/" class="menu-link">Tags</a>                  
            </li>
          
            <li class="menu-item">
              <a href="/series/" class="menu-link">Series</a>                  
            </li>
          
            <li class="menu-item">
              <a href="/project-types/" class="menu-link">Project Types</a>                  
            </li>
          
        </ul>
      </li>
      
      
      <li class="menu-item--align">
        <div class="switch">
          <input class="switch-input" type="checkbox" id="themeSwitch">
          <label aria-hidden="true" class="switch-label" for="themeSwitch">On</label>
          <div aria-hidden="true" class="switch-marker"></div>
        </div>
      </li>
    </ul>
    <span class="nav-toggle" id="js-navbar-toggle">
      <svg xmlns="http://www.w3.org/2000/svg" id="Outline" viewBox="0 0 24 24" width="30" height="30" fill="var(--color-contrast-high)"><rect y="11" width="24" height="2" rx="1"/><rect y="4" width="24" height="2" rx="1"/><rect y="18" width="24" height="2" rx="1"/></svg>
    </span>
  </nav>
</header><main class="section">
<div class="container">
  <section class="page-header">
    <h1 class="page-header-title">Building a Thread Pool in C&#43;&#43;</h1>
    <div class="post-list-meta">
      <div class="post-list-dates">Sep 5, 2024&nbsp;&middot;&nbsp;9 min.</div>
      
      <div class="post-list-categories">
        
          <a href="//localhost:52441/categories/engineering/">Engineering</a>
        
      </div>
      
      
    </div>
    <p class="page-header-desc"></p>
    <div class="single-terms">
      
      
      <a class="term" href="//localhost:52441/tags/c&#43;&#43;/">C&#43;&#43;</a></li>
      
      
    </div>
  </section>
</div>
<div class="single-container-post">
  

  <aside class="toc">
    <div id="js-toc-toggle">
      <h2 class="toc-header">Table of Contents</h2>
      <span class="toc-drop-icon">&blacktriangledown;</span>
    </div>
    <div id="js-toc-contents" class="toc-contents"><nav id="TableOfContents"></nav></div>
  </aside>

  <div class="single-post-contents">
      <div class="series">
        <p>Part of the <a href="//localhost:52441/series/c&#43;&#43;/">C&#43;&#43;</a> series:</p>
        
        <ol class="series-list">
            <li>
                <a href="//localhost:52441/engineering/compilers/">C&#43;&#43; Compilers</a>
              
            </li>
            <li>
                <a href="//localhost:52441/engineering/microbenchmarking-in-c-/">Microbenchmarking in C&#43;&#43;</a>
              
            </li>
            <li>
                <a href="//localhost:52441/engineering/constructors-and-move-semantics-in-cpp/">Constructors and Move Semantics in C&#43;&#43;</a>
              
            </li>
            <li>
                <a href="//localhost:52441/engineering/compile-time-programming-in-c-/">Compile-Time Programming in C&#43;&#43;</a>
              
            </li>
            <li>
                <a href="//localhost:52441/engineering/building-neural-networks-in-c-/">Building Neural Networks in C&#43;&#43;</a>
              
            </li>
            <li>
                <a href="//localhost:52441/engineering/concurrency-in-c-/">Concurrency in C&#43;&#43;</a>
              
            </li>
            <li>Building a Thread Pool in C&#43;&#43;<span class="series-this-post">This post!</span>
              
            </li>
            <li>
                <a href="//localhost:52441/engineering/building-a-log-utility-class-in-cpp/">Building a Log Utility Class in C&#43;&#43;</a>
              
            </li>
            <li>
                <a href="//localhost:52441/engineering/functional-programming-in-c-/">Functional Programming in C&#43;&#43;</a>
              
            </li>
        </ol>
      </div>
    
    <div class="single-feature-img">



  

</div>
    <article class="markdown">
        <p>One of my pet projects over the past few years has been my deep learning framework, built entirely in C++ <a href="https://www.christopher-weaver.com/projects/portfolio-project-1/" target="_blank" rel="noopener">link</a>. Once I had an initial iteration that worked sequentially and could successfully train a neural network to accomplish specific tasks, I turned toward leveraging concurrency to speed up training. My first thought was to farm out computationally expensive tasks to different CPU cores, primarily focusing on functions that perform computations on matrices.</p>
<p>In my project, I have a set of polymorphic classes that represent different types of neural network layers (like a dense layer, input layer, flatten layer, etc.). Each initialized class owns its matrix of weights and, upon receiving an input matrix, performs some computations between the two and sends out an output matrix. These matrices are often tens of thousands of values in size, which provided a good opportunity for multi-threading computations. For example, with my matrix multiplication function, I did the following:</p>
<p>Lookup how many cores I have on the machine.
Break up the matrix into separate equal parts matching the number of available cores. I don’t actually break apart the matrix; I generate index ranges to represent dividing the matrix.
Create a new task that uses my matrix multiplication function with parameters representing the bounding index.
Once all tasks are complete, each task is deleted via RAII.
This approach worked, and I saw significant improvement in my training times. However, the inefficiency of creating and destroying tasks every time a neural layer performed forward propagation (which usually happens thousands of times during a training session) was obviously not efficient and bothered me. The solution was not to constantly create and destroy threads, but instead to generate the number of threads to match the number of cores on a machine at the beginning of the program, and continuously use those same threads throughout the program&rsquo;s lifetime in a thread pool. Here&rsquo;s how I did that in C++:</p>
<p>I decided that each neural layer should own its own ThreadPool class. The ThreadPool class would be responsible for managing its threads throughout the program&rsquo;s lifetime, including the management of all tasks sent its way. The public interface of this class looks like this:</p>


  <span class="code-language">C&#43;&#43;</span><div class="highlight"><pre tabindex="0" style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-C++" data-lang="C++"><span style="display:flex;"><span>    <span style="color:#6ab825;font-weight:bold">class</span> <span style="color:#447fcf;text-decoration:underline">Thread_Pool</span> {
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        Thread_Pool();
</span></span><span style="display:flex;"><span>        ~Thread_Pool();
</span></span><span style="display:flex;"><span>        <span style="color:#6ab825;font-weight:bold">void</span> <span style="color:#447fcf">setupPool</span>(size_t threads);
</span></span><span style="display:flex;"><span>        <span style="color:#6ab825;font-weight:bold">void</span> <span style="color:#447fcf">clearPool</span>();
</span></span><span style="display:flex;"><span>        <span style="color:#6ab825;font-weight:bold">void</span> <span style="color:#447fcf">wait</span>();
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#6ab825;font-weight:bold">template</span>&lt;<span style="color:#6ab825;font-weight:bold">typename</span> F, <span style="color:#6ab825;font-weight:bold">typename</span>... Args&gt;
</span></span><span style="display:flex;"><span>        <span style="color:#6ab825;font-weight:bold">void</span> enqueue(F&amp;&amp;f, Args&amp;&amp;... args);
</span></span><span style="display:flex;"><span>    };</span></span></code></pre></div>
<p>I decided I only wanted to utilize this thread pool during training when the mini-batch size is equal to or larger than the number of cores on the machine. From my testing, the overhead of using threads outweighs the performance gains of concurrency when the matrix sizes are too small. To accommodate this, the default constructor does not do much. Instead, when my program needs to use the thread pool, each layer calls the setupPool() function to initialize the thread pool with the appropriate number of threads. The clearPool() method does cleanup when training is complete, and the thread pool is no longer needed (the destructor will also call this method). This approach leaves room for mistakes since some of the initial state management is outside the constructor, but I felt it was a worthy tradeoff in this case. The enqueue function takes a task the neural layer needs to complete and assigns it to a thread. The wait() function is called anytime we want our neural layer class to hold until the Thread_Pool has no further work.</p>
<p>The private members and functions look like this:</p>


  <span class="code-language">C&#43;&#43;</span><div class="highlight"><pre tabindex="0" style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-C++" data-lang="C++"><span style="display:flex;"><span>    std::vector&lt;std::<span style="color:#6ab825;font-weight:bold">thread</span>&gt; workers;
</span></span><span style="display:flex;"><span>    std::vector&lt;std::function&lt;<span style="color:#6ab825;font-weight:bold">void</span>()&gt;&gt; tasks;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#6ab825;font-weight:bold">void</span> <span style="color:#447fcf">worker</span>();
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    std::mutex queueMutex;
</span></span><span style="display:flex;"><span>    std::condition_variable condition;
</span></span><span style="display:flex;"><span>    std::condition_variable finishedCondition;
</span></span><span style="display:flex;"><span>    std::atomic&lt;<span style="color:#6ab825;font-weight:bold">bool</span>&gt; stop{<span style="color:#24909d">false</span>};
</span></span><span style="display:flex;"><span>    std::atomic&lt;<span style="color:#6ab825;font-weight:bold">int</span>&gt; activeTasks{<span style="color:#3677a9">0</span>};</span></span></code></pre></div>
<p>I will go over these more in detail as we further evaluate our implementation details. Starting with our setupPool function</p>


  <span class="code-language">C&#43;&#43;</span><div class="highlight"><pre tabindex="0" style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-C++" data-lang="C++"><span style="display:flex;"><span><span style="color:#6ab825;font-weight:bold">void</span> Thread_Pool::setupPool(size_t threads) {
</span></span><span style="display:flex;"><span>    stop = <span style="color:#24909d">false</span>;
</span></span><span style="display:flex;"><span>    <span style="color:#6ab825;font-weight:bold">for</span> (size_t i = <span style="color:#3677a9">0</span>; i &lt; threads; i++) {
</span></span><span style="display:flex;"><span>        workers.emplace_back(&amp;Thread_Pool::worker::<span style="color:#6ab825;font-weight:bold">this</span>);
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>}</span></span></code></pre></div>
<p>This function is called by the neural layer class when it determines that the thread pool is appropriate. The threads variable always matches the number of cores on a machine by passing this variable:</p>


  <span class="code-language">C&#43;&#43;</span><div class="highlight"><pre tabindex="0" style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-C++" data-lang="C++"><span style="display:flex;"><span>    <span style="color:#6ab825;font-weight:bold">const</span> <span style="color:#6ab825;font-weight:bold">auto</span> processor_count = std::<span style="color:#6ab825;font-weight:bold">thread</span>::hardware_concurrency();</span></span></code></pre></div>
<p>We construct the appropriate number of threads and place them into our thread vector called workers, where they will live throughout their lifetime. Each thread will run the worker(), which looks like this:</p>


  <span class="code-language">C&#43;&#43;</span><div class="highlight"><pre tabindex="0" style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-C++" data-lang="C++"><span style="display:flex;"><span>    <span style="color:#6ab825;font-weight:bold">void</span> Thread_Pool::worker() {
</span></span><span style="display:flex;"><span>        <span style="color:#6ab825;font-weight:bold">while</span> (<span style="color:#24909d">true</span>) {
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>            std::function&lt;<span style="color:#6ab825;font-weight:bold">void</span>()&gt; task;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>            {
</span></span><span style="display:flex;"><span>                std::unique_lock&lt;std::mutex&gt; lock(queueMutex);
</span></span><span style="display:flex;"><span>                condition.wait(lock, [<span style="color:#6ab825;font-weight:bold">this</span>]() {
</span></span><span style="display:flex;"><span>                    <span style="color:#6ab825;font-weight:bold">return</span> stop || !task.empty();
</span></span><span style="display:flex;"><span>                });
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>                <span style="color:#6ab825;font-weight:bold">if</span> (stop) {
</span></span><span style="display:flex;"><span>                    <span style="color:#6ab825;font-weight:bold">return</span>;
</span></span><span style="display:flex;"><span>                }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>                task = std::move(tasks.front());
</span></span><span style="display:flex;"><span>                tasks.pop();
</span></span><span style="display:flex;"><span>            }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>            task();
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>      
</span></span><span style="display:flex;"><span>            activeTasks--;
</span></span><span style="display:flex;"><span>            finishedCondition.notify_one();
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>    }</span></span></code></pre></div>
<p>We want to ensure each thread is kept alive and ready for work when the time comes, so the worker() function runs a while(true) loop. However, the thread will often have no work to do, which is why we call the wait() function on our private condition variable. The condition variable locks our queueMutex mutex until the lambda we pass it returns true. The best part is that the thread itself goes to sleep and doesn’t continuously check the lambda, alleviating CPU overhead. Instead, it waits for us to call condition.notify_one(), which we do elsewhere in the class. The condition checks two things: first, whether we’ve asked the Thread_Pool class to stop. If so, it continues, and we check if stop == true. If it is, we exit the while loop. The other check is whether our tasks queue has something in it. If it’s not empty, we assign the front item to the task variable and pop it off the queue. At this point, we can release our mutex, allowing other threads to safely pull from the tasks queue without a race condition. The thread then executes the task, decrements the activeTasks, and notifies the finishedCondition that one task is done.</p>
<p>Often, I break down my matrix into its indexed ranges and then call enqueue() on the Thread_Pool class in a loop to concurrently process subsets of the matrix on different cores. Here, it’s important for the neural layer to wait for all cores to finish processing their part of the matrix. The neural layer calls wait(), which causes the thread pool class to block until all tasks are completed. The wait() function looks like this:</p>


  <span class="code-language">C&#43;&#43;</span><div class="highlight"><pre tabindex="0" style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-C++" data-lang="C++"><span style="display:flex;"><span>    <span style="color:#6ab825;font-weight:bold">void</span> Thread_Pool::wait() {
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        std::unique_lock&lt;std::mutex&gt; lock(queueMutex);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        finishedCondition.wait(lock, [<span style="color:#6ab825;font-weight:bold">this</span>]() {
</span></span><span style="display:flex;"><span>            <span style="color:#6ab825;font-weight:bold">return</span> stop || (tasks.empty() &amp;&amp; activeTasks == <span style="color:#3677a9">0</span>);
</span></span><span style="display:flex;"><span>        })
</span></span><span style="display:flex;"><span>    }</span></span></code></pre></div>
<p>The finished condition checks to see if the tasks queue is empty and activeTasks == 0 (meaning all tasks are not only off the queue but completed). If these conditions aren’t met, the main thread the neural layer runs on is put to sleep. Anytime we complete a task in worker() and call finishedCondition.notify_one(), we check again to see if we can end the wait() and hand control back to the neural layer.</p>
<p>Adding tasks to the thread pool is one of the harder challenges and requires meta-programming and a template parameter pack since we need it to handle any task given by the neural layer (as long as no return value is expected). This is the job of the enqueue() function, which generally gets called like this:</p>


  <span class="code-language">C&#43;&#43;</span><div class="highlight"><pre tabindex="0" style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-C++" data-lang="C++"><span style="display:flex;"><span>    <span style="color:#6ab825;font-weight:bold">const</span> <span style="color:#6ab825;font-weight:bold">auto</span> processor_count = std::<span style="color:#6ab825;font-weight:bold">thread</span>::hardware_concurrency();
</span></span><span style="display:flex;"><span>    <span style="color:#6ab825;font-weight:bold">for</span> (<span style="color:#6ab825;font-weight:bold">int</span> i = <span style="color:#3677a9">0</span>; i &lt; processor_count - <span style="color:#3677a9">1</span>; i++) {
</span></span><span style="display:flex;"><span>        _threadPool.enqueue(&amp;Tensor::MatmulInner&lt;a_f&gt;,
</span></span><span style="display:flex;"><span>                                <span style="color:#6ab825;font-weight:bold">this</span>,
</span></span><span style="display:flex;"><span>                                std::ref(m1),
</span></span><span style="display:flex;"><span>                                std::ref(m2),
</span></span><span style="display:flex;"><span>                                bias,
</span></span><span style="display:flex;"><span>                                i * dimensions_per_thread,
</span></span><span style="display:flex;"><span>                                dimensions_per_thread,
</span></span><span style="display:flex;"><span>                                af);
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>    _threadPool.wait();</span></span></code></pre></div>
<p>A lot of the parameters passed won’t make sense without further context about the program, but that’s part of the point. The enqueue() function doesn’t need to understand the parameters passed to it; it just needs to ensure they can be executed by a thread. The enqueue() function works like this:</p>


  <span class="code-language">C&#43;&#43;</span><div class="highlight"><pre tabindex="0" style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-C++" data-lang="C++"><span style="display:flex;"><span>    <span style="color:#6ab825;font-weight:bold">template</span>&lt;<span style="color:#6ab825;font-weight:bold">typename</span>... F, Args... args&gt;
</span></span><span style="display:flex;"><span>    <span style="color:#6ab825;font-weight:bold">void</span> enqueue(F&amp;&amp; f, Args&amp;&amp;... args) {
</span></span><span style="display:flex;"><span>        {
</span></span><span style="display:flex;"><span>            std::unique_lock&lt;std::mutex&gt; lock(queueMutex);
</span></span><span style="display:flex;"><span>            tasks.emplace([f = std::forward&lt;F&gt;(f), ...args = std::forward&lt;Args&gt;(args)]() <span style="color:#6ab825;font-weight:bold">mutable</span> {
</span></span><span style="display:flex;"><span>                <span style="color:#6ab825;font-weight:bold">if</span> <span style="color:#447fcf">constexpr</span> (std::is_member_function_pointer&lt;F&gt;::value) {
</span></span><span style="display:flex;"><span>                    std::invoke(f, std::foward&lt;Args&gt;(args)...);
</span></span><span style="display:flex;"><span>                } <span style="color:#6ab825;font-weight:bold">else</span> {
</span></span><span style="display:flex;"><span>                    f(std::foward&lt;Args&gt;(args)...);
</span></span><span style="display:flex;"><span>                }
</span></span><span style="display:flex;"><span>            });
</span></span><span style="display:flex;"><span>            activeTasks++;
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>        condition.notify_one();
</span></span><span style="display:flex;"><span>    }</span></span></code></pre></div>
<p>Because I want to accept any function with an arbitrary number of arguments, we use templates with a template paramter pack to capture the arguments. I capture these parameters as rvalues (&amp;&amp;) in order to ensure we can bind to both rvalues and lvalues, but this will require us to use perfect forwarding later on. I next lock the queueMutex to ensure no thread attempts to modify the tasks queue prior to me getting a new task on it. I then attempt to add a new std::function<void> task to the tasks queue that will represent the function I want my task to execute. I do this by emplacing a lambda that captures the f and args. I call std::foward on both these because I want to ensure if these values are initially passed as lvalues that I make copies and if they are passed by rvalues that I properly move them. This task will modify matrices and I therefore mark the lambda as mutable. I next utilize SFINAE by checking to see if f is a member function pointer (f is a pointer to a member function of a class, which it will be in all my uses). If it is, we need to use std::invoke to ensure correct calling semantics where the first arguments is typically an instance of the class. Otherwise, we can directly have the lambda call the f function. These are compile time checks so they should have little to no impact on our runtime. Once we have added the task lambda to our tasks queue, we can increment our activeTasks tracker, release the queueMutex and notify our condition variable that as task is ready. We saw earlier in our worker() that a notified condition variable will check to see if there is something in the task queue, grab it, and execute it.</p>
<p>Finally we need to implement the cleanup of the class which lives within the clearPool()</p>


  <span class="code-language">C&#43;&#43;</span><div class="highlight"><pre tabindex="0" style="color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-C++" data-lang="C++"><span style="display:flex;"><span>    <span style="color:#6ab825;font-weight:bold">void</span> Thread_Pool::clearPool() {
</span></span><span style="display:flex;"><span>        {
</span></span><span style="display:flex;"><span>            std::unique_lock&lt;std::mutex&gt; lock(queueMutex);
</span></span><span style="display:flex;"><span>            stop = <span style="color:#24909d">true</span>;
</span></span><span style="display:flex;"><span>            condition.notify_all();
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>        <span style="color:#6ab825;font-weight:bold">for</span> (std::<span style="color:#6ab825;font-weight:bold">thread</span> &amp;worker : workers) {
</span></span><span style="display:flex;"><span>            <span style="color:#6ab825;font-weight:bold">if</span> (worker.joinable()) {
</span></span><span style="display:flex;"><span>                worker.join();
</span></span><span style="display:flex;"><span>            }
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        workers.clear();
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        std::queue&lt;std::function&lt;<span style="color:#6ab825;font-weight:bold">void</span>()&gt;&gt; empty;
</span></span><span style="display:flex;"><span>        std::swap(tasks,empty);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        activeTasks = <span style="color:#3677a9">0</span>;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        finishedCondition.notify_all();
</span></span><span style="display:flex;"><span>    }</span></span></code></pre></div>
<p>We set all our invariants to values that signal no further work is needed for the threads in our thread pool. We join our threads, clear our workers vector in which our threads live, we ensure our threads queue is empty, and notify our finishedCondition just in case a thread is being blocked by our wait() function. This function is utilized by my neural net when switching from training to inference and no longer needs the concurrency a thread pool provides. I also call this function from the destructor for RAII.</p>
<p>Thread pools are great. They provide utilization of multiple cpu cores with little overhead while often hidding implementation details we prefer to keep out of other parts of our program. Part of what makes this work so well is there is little to no communication needed between threads. Each thread works completely independent of the rest, which often is not the case. When threads need to pass information between them, better (more complex options) such as programming thread affinities might be required.</p>

    </article>
    <aside>
      <div class="single-terms">
        
          
          <a class="term" href="//localhost:52441/tags/c&#43;&#43;/">C&#43;&#43;</a></li>
          
        
      </div>
      
  
  
  

  <section>
    <h2>Share</h2>
    <div class="social-links">
      <ul class="social-icons--share">
        
        
        <a href="https://twitter.com/intent/tweet?url=%2f%2flocalhost%3a52441%2fengineering%2fbuilding-a-thread-pool%2f&amp;text=Building%20a%20Thread%20Pool%20in%20C%2b%2b" target="_blank" rel="noopener" aria-label="Share on Twitter" class="social-btn twitter">
          <li><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-twitter" width="24" height="24" viewBox="0 0 384 312" fill="var(--color-primary)"><path d="m384 36.9c-14.1 6.3-29.3 10.5-45.2 12.4 16.3-9.7 28.8-25.2 34.6-43.6-15.2 9-32.1 15.6-50 19.1-14.4-15.2-34.9-24.8-57.5-24.8-43.5 0-78.8 35.3-78.8 78.8 0 6.2.7 12.2 2 17.9-65.5-3.3-123.5-34.6-162.4-82.3-6.7 11.6-10.6 25.2-10.6 39.6 0 27.3 13.9 51.4 35 65.6-12.9-.4-25.1-4-35.7-9.9v1c0 38.2 27.2 70 63.2 77.2-6.6 1.8-13.6 2.8-20.8 2.8-5.1 0-10-.5-14.8-1.4 10 31.3 39.1 54.1 73.6 54.7-27 21.1-60.9 33.7-97.8 33.7-6.4 0-12.6-.4-18.8-1.1 34.9 22.4 76.3 35.4 120.8 35.4 144.9 0 224.1-120 224.1-224.1 0-3.4-.1-6.8-.2-10.2 15.4-11.1 28.7-25 39.3-40.8z"/></svg></li>
        </a>
        
        
        
        
        
        
        
        <a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=%2f%2flocalhost%3a52441%2fengineering%2fbuilding-a-thread-pool%2f&amp;source=%2f%2flocalhost%3a52441%2fengineering%2fbuilding-a-thread-pool%2f&amp;title=Building%20a%20Thread%20Pool%20in%20C%2b%2b&amp;summary=Building%20a%20Thread%20Pool%20in%20C%2b%2b" target="_blank" rel="noopener" aria-label="Share on LinkedIn" class="social-btn linkedin">
          <li><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-linkedin" width="24" height="24" viewBox="0 0 352 352" fill="var(--color-primary)"><path d="M0,40v272c0,21.9,18.1,40,40,40h272c21.9,0,40-18.1,40-40V40c0-21.9-18.1-40-40-40H40C18.1,0,0,18.1,0,40z M312,32 c4.6,0,8,3.4,8,8v272c0,4.6-3.4,8-8,8H40c-4.6,0-8-3.4-8-8V40c0-4.6,3.4-8,8-8H312z M59.5,87c0,15.2,12.3,27.5,27.5,27.5 c15.2,0,27.5-12.3,27.5-27.5c0-15.2-12.3-27.5-27.5-27.5C71.8,59.5,59.5,71.8,59.5,87z M187,157h-1v-21h-45v152h47v-75 c0-19.8,3.9-39,28.5-39c24.2,0,24.5,22.4,24.5,40v74h47v-83.5c0-40.9-8.7-72-56.5-72C208.5,132.5,193.3,145.1,187,157z M64,288h47.5 V136H64V288z"/></svg></li>
        </a>
        
        
        
        <a href="mailto:?subject=Christopher%20Weaver%20-%20Building%20a%20Thread%20Pool%20in%20C%2b%2b.&amp;body=Building%20a%20Thread%20Pool%20in%20C%2b%2b%2c%20by%20Christopher%20Weaver%0a%0a%0a%2f%2flocalhost%3a52441%2fengineering%2fbuilding-a-thread-pool%2f%0a" target="_blank" class="social-btn email">
          <li><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-mail" width="24" height="24" viewBox="0 0 416 288" fill="var(--color-primary)"><path d="m0 16v256 16h16 384 16v-16-256-16h-16-384-16zm347 16-139 92.5-139-92.5zm-148 125.5 9 5.5 9-5.5 167-111.5v210h-352v-210z"/></svg></li>
        </a>
      </ul>
    </div>
  </section>
  
        <div class="series">
          <p>Part of the <a href="//localhost:52441/series/c&#43;&#43;/">C&#43;&#43;</a> series:</p>
          
          <ol>
              <li>
                  <a href="//localhost:52441/engineering/compilers/">C&#43;&#43; Compilers</a>
                
              </li>
              <li>
                  <a href="//localhost:52441/engineering/microbenchmarking-in-c-/">Microbenchmarking in C&#43;&#43;</a>
                
              </li>
              <li>
                  <a href="//localhost:52441/engineering/constructors-and-move-semantics-in-cpp/">Constructors and Move Semantics in C&#43;&#43;</a>
                
              </li>
              <li>
                  <a href="//localhost:52441/engineering/compile-time-programming-in-c-/">Compile-Time Programming in C&#43;&#43;</a>
                
              </li>
              <li>
                  <a href="//localhost:52441/engineering/building-neural-networks-in-c-/">Building Neural Networks in C&#43;&#43;</a>
                
              </li>
              <li>
                  <a href="//localhost:52441/engineering/concurrency-in-c-/">Concurrency in C&#43;&#43;</a>
                
              </li>
              <li>Building a Thread Pool in C&#43;&#43;<span class="series-this-post">This post!</span>
                
              </li>
              <li>
                  <a href="//localhost:52441/engineering/building-a-log-utility-class-in-cpp/">Building a Log Utility Class in C&#43;&#43;</a>
                
              </li>
              <li>
                  <a href="//localhost:52441/engineering/functional-programming-in-c-/">Functional Programming in C&#43;&#43;</a>
                
              </li>
          </ol>
        </div>
      
      
    </aside>
  </div>
</div>

    </main><footer>
  
  <div class="section footer">
    <p class="footer-copyright">&copy; 2025 &middot; 
      <a href="//localhost:52441/">Christopher Weaver</a>
      
    </p>
    
      <div class="footer-socials">
        
<div class="social-links">
  <ul class="social-icons">
    
    

    
    

    
    
    <li>
      <a href="https://github.com/crweaver225" target="_blank" rel="noopener" aria-label="Visit Github profile" class="social-btn github">
        <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-github" width="24" height="24" viewBox="0 0 24 24" fill="var(--color-primary)"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"/></svg>
      </a>
    </li>
    

    
    

    
    
    <li>
      <a href="https://www.linkedin.com/in/christopher-weaver" target="_blank" rel="noopener" aria-label="Visit LinkedIn profile" class="social-btn linkedin">
        <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-linkedin" width="24" height="24" viewBox="0 0 352 352" fill="var(--color-primary)"><path d="M0,40v272c0,21.9,18.1,40,40,40h272c21.9,0,40-18.1,40-40V40c0-21.9-18.1-40-40-40H40C18.1,0,0,18.1,0,40z M312,32 c4.6,0,8,3.4,8,8v272c0,4.6-3.4,8-8,8H40c-4.6,0-8-3.4-8-8V40c0-4.6,3.4-8,8-8H312z M59.5,87c0,15.2,12.3,27.5,27.5,27.5 c15.2,0,27.5-12.3,27.5-27.5c0-15.2-12.3-27.5-27.5-27.5C71.8,59.5,59.5,71.8,59.5,87z M187,157h-1v-21h-45v152h47v-75 c0-19.8,3.9-39,28.5-39c24.2,0,24.5,22.4,24.5,40v74h47v-83.5c0-40.9-8.7-72-56.5-72C208.5,132.5,193.3,145.1,187,157z M64,288h47.5 V136H64V288z"/></svg>
        </a>
    </li>
    

    
    
    <li>
      <a href="mailto:?to=crweaver225%40yahoo.com" target="_blank" class="social-btn email">
        <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-mail" width="24" height="24" viewBox="0 0 416 288" fill="var(--color-primary)"><path d="m0 16v256 16h16 384 16v-16-256-16h-16-384-16zm347 16-139 92.5-139-92.5zm-148 125.5 9 5.5 9-5.5 167-111.5v210h-352v-210z"/></svg>
      </a>
    </li>
    
  </ul>
</div>

      </div>
    
  </div>
</footer>
  
  





  
  
  
    <script src="//localhost:52441/custom.js"></script>
  




  

<script src="//localhost:52441/main.js"></script>


</body>
</html>
